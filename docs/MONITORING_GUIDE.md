# Chat4All - Guia de Monitoramento

## ðŸŽ¯ Acesso RÃ¡pido

### Prometheus
- **URL:** http://localhost:9090
- **FunÃ§Ã£o:** Coleta e armazena mÃ©tricas de todos os serviÃ§os
- **Principais queries:**
  - Total de requisiÃ§Ãµes: `grpc_requests_total`
  - Taxa de sucesso: `(1 - (rate(grpc_requests_failed_total[5m]) / rate(grpc_requests_total[5m]))) * 100`
  - LatÃªncia P99: `histogram_quantile(0.99, rate(grpc_request_duration_seconds_bucket[5m]))`

### Grafana
- **URL:** http://localhost:3000
- **Credenciais:** admin / admin
- **Dashboards disponÃ­veis:**
  - Chat4All - System Overview (visÃ£o geral do sistema)

---

## ðŸ“Š Dashboards Grafana

### 1. System Overview
**Arquivo:** `monitoring/grafana/dashboards/1-overview.json`

**PainÃ©is incluÃ­dos:**

#### Status dos ServiÃ§os
- **API Service Status**: Mostra se API estÃ¡ UP/DOWN
- **Router Worker Status**: Mostra se Worker estÃ¡ UP/DOWN
- Cores: ðŸŸ¢ Verde (UP) | ðŸ”´ Vermelho (DOWN)

#### MÃ©tricas de Desempenho
- **Success Rate (5m)**: Taxa de sucesso nas Ãºltimas 5 minutos
  - ðŸŸ¢ Verde: â‰¥ 99.5%
  - ðŸŸ¡ Amarelo: 95-99.5%
  - ðŸ”´ Vermelho: < 95%

- **P99 Latency**: LatÃªncia no percentil 99
  - ðŸŸ¢ Verde: < 100ms
  - ðŸŸ¡ Amarelo: 100-200ms
  - ðŸ”´ Vermelho: > 200ms
  - **Target:** < 200ms (RNF-006)

- **Total Requests**: Contador total de requisiÃ§Ãµes processadas

#### GrÃ¡ficos Temporais

**gRPC Request Rate:**
- Total Requests/s (linha azul)
- Failed Requests/s (linha vermelha)
- Mostra carga em tempo real
- Atualiza a cada 5 segundos

**gRPC Latency Percentiles:**
- P50 (mediana) - verde
- P95 - amarelo
- P99 (target < 200ms) - vermelho
- Linha vermelha horizontal em 0.2s indica threshold

**EstatÃ­sticas exibidas:**
- Mean (mÃ©dia)
- Last (Ãºltimo valor)
- Max (valor mÃ¡ximo)

---

## ðŸ” Prometheus - MÃ©tricas DisponÃ­veis

### API Service (porta 8080)

#### MÃ©tricas de RequisiÃ§Ãµes gRPC
```promql
# Total de requisiÃ§Ãµes
grpc_requests_total

# RequisiÃ§Ãµes falhas
grpc_requests_failed_total

# Taxa de erro (percentual)
(rate(grpc_requests_failed_total[1m]) / rate(grpc_requests_total[1m])) * 100

# Taxa de sucesso (percentual)
(1 - (rate(grpc_requests_failed_total[5m]) / rate(grpc_requests_total[5m]))) * 100
```

#### MÃ©tricas de LatÃªncia
```promql
# LatÃªncia P50 (mediana)
histogram_quantile(0.50, rate(grpc_request_duration_seconds_bucket[5m]))

# LatÃªncia P95
histogram_quantile(0.95, rate(grpc_request_duration_seconds_bucket[5m]))

# LatÃªncia P99 (SLA < 200ms)
histogram_quantile(0.99, rate(grpc_request_duration_seconds_bucket[5m]))
```

#### MÃ©tricas de Mensagens
```promql
# Total de mensagens enviadas
messages_sent_total

# Taxa de envio (msg/s)
rate(messages_sent_total[1m])

# Total de mensagens entregues
messages_delivered_total

# Taxa de entrega (msg/s)
rate(messages_delivered_total[1m])
```

#### MÃ©tricas de Upload/Download de Arquivos
```promql
# Total de uploads
file_upload_total

# Total de downloads
file_download_total

# Tamanho dos arquivos (bytes)
file_upload_size_bytes
```

### Router Worker (porta 8082)

```promql
# Mensagens consumidas do Kafka
messages_consumed_total{topic="messages"}

# Mensagens processadas com sucesso
messages_processed_total{status="success"}

# Mensagens falhadas
messages_failed_total

# Tempo de processamento
processing_duration_seconds

# Tempo de escrita no Cassandra
cassandra_write_duration_seconds
```

### WebSocket Gateway (porta 9095)

```promql
# ConexÃµes ativas
websocket_connections_active

# NotificaÃ§Ãµes enviadas
websocket_notifications_sent_total

# Taxa de notificaÃ§Ãµes
rate(websocket_notifications_sent_total[1m])
```

---

## ðŸ“ˆ Queries Ãšteis para Monitoramento

### SLA e Disponibilidade

#### Uptime dos ServiÃ§os
```promql
# Verifica quais serviÃ§os estÃ£o UP
up{job=~"api-service|router-worker|websocket-gateway"}

# Tempo UP nas Ãºltimas 24h (percentual)
avg_over_time(up{job="api-service"}[24h]) * 100
```

#### Taxa de Sucesso (SLA â‰¥ 99.95%)
```promql
# Taxa de sucesso nas Ãºltimas 5 minutos
(1 - (rate(grpc_requests_failed_total[5m]) / rate(grpc_requests_total[5m]))) * 100

# Taxa de sucesso nas Ãºltimas 24 horas
(1 - (rate(grpc_requests_failed_total[24h]) / rate(grpc_requests_total[24h]))) * 100
```

### Performance

#### Throughput (RequisiÃ§Ãµes por Segundo)
```promql
# RequisiÃ§Ãµes/segundo nas Ãºltimas 1 min
rate(grpc_requests_total[1m])

# RequisiÃ§Ãµes/segundo nas Ãºltimas 5 min
rate(grpc_requests_total[5m])

# Pico de requisiÃ§Ãµes (mÃ¡ximo em 1h)
max_over_time(rate(grpc_requests_total[1m])[1h:1m])
```

#### LatÃªncia por Percentil
```promql
# P50, P95, P99 em uma query
histogram_quantile(0.50, rate(grpc_request_duration_seconds_bucket[5m]))
histogram_quantile(0.95, rate(grpc_request_duration_seconds_bucket[5m]))
histogram_quantile(0.99, rate(grpc_request_duration_seconds_bucket[5m]))
```

### AnÃ¡lise de Erros

#### Taxa de Erro
```promql
# Erros por segundo
rate(grpc_requests_failed_total[1m])

# Percentual de erro
(rate(grpc_requests_failed_total[1m]) / rate(grpc_requests_total[1m])) * 100
```

#### Identificar Picos de Erro
```promql
# Pico de erros na Ãºltima hora
max_over_time(rate(grpc_requests_failed_total[1m])[1h:1m])

# Delta de erros (variaÃ§Ã£o)
delta(grpc_requests_failed_total[5m])
```

---

## ðŸš¨ Alertas Prometheus

### Alertas Configurados

Os alertas estÃ£o definidos em `monitoring/prometheus-alerts.yml`:

#### Alertas CrÃ­ticos (SLA Impact)

**APIServiceDown:**
- CondiÃ§Ã£o: `up{job="api-service"} == 0`
- DuraÃ§Ã£o: > 1 minuto
- Severidade: CRITICAL
- Impacto: UsuÃ¡rios nÃ£o podem enviar/receber mensagens

**RouterWorkerDown:**
- CondiÃ§Ã£o: `up{job="router-worker"} == 0`
- DuraÃ§Ã£o: > 2 minutos
- Severidade: CRITICAL
- Impacto: Mensagens nÃ£o sendo processadas

**HighLatencyP99:**
- CondiÃ§Ã£o: P99 > 200ms
- DuraÃ§Ã£o: > 5 minutos
- Severidade: WARNING
- Impacto: UsuÃ¡rios com respostas lentas

**HighErrorRate:**
- CondiÃ§Ã£o: Taxa de erro > 1%
- DuraÃ§Ã£o: > 2 minutos
- Severidade: WARNING
- Impacto: Falhas em requisiÃ§Ãµes

---

## ðŸ”§ ConfiguraÃ§Ã£o

### Prometheus

**Arquivo:** `monitoring/prometheus.yml`

**Intervalos de Scrape:**
- API Service: 5s
- Router Worker: 5s
- WebSocket Gateway: 5s
- Prometheus (self): 15s

**RetenÃ§Ã£o de Dados:** PadrÃ£o (15 dias)

**Recarregar configuraÃ§Ã£o sem reiniciar:**
```bash
curl -X POST http://localhost:9090/-/reload
```

### Grafana

**Provisioning AutomÃ¡tico:**
- Datasource: `monitoring/grafana/provisioning/datasources/prometheus.yml`
- Dashboards: `monitoring/grafana/provisioning/dashboards/dashboards.yml`

**Dashboards:**
- Path: `monitoring/grafana/dashboards/`
- Auto-load: Sim (a cada 10 segundos)

**Criar novo dashboard:**
1. Copiar dashboard existente em `monitoring/grafana/dashboards/`
2. Modificar JSON
3. Aguardar 10 segundos ou reiniciar Grafana

---

## ðŸ“‹ Checklist de ValidaÃ§Ã£o

### âœ… Verificar Monitoramento Funcionando

**Prometheus:**
```bash
# Verificar status
curl -s http://localhost:9090/-/healthy

# Ver targets (todos devem estar "up")
curl -s http://localhost:9090/api/v1/targets | jq -r '.data.activeTargets[] | "\(.labels.job): \(.health)"'

# Executar query de teste
curl -s 'http://localhost:9090/api/v1/query?query=up' | jq '.data.result'
```

**Grafana:**
```bash
# Verificar status
curl -s http://localhost:3000/api/health

# Listar datasources
curl -s -u admin:admin http://localhost:3000/api/datasources | jq '.[].name'

# Listar dashboards
curl -s -u admin:admin http://localhost:3000/api/search | jq '.[] | {title, uid}'
```

### âœ… MÃ©tricas de ValidaÃ§Ã£o

ApÃ³s enviar mensagens de teste, verificar:

1. **Total de requisiÃ§Ãµes aumentando:**
   ```promql
   grpc_requests_total
   ```

2. **Sem falhas:**
   ```promql
   grpc_requests_failed_total
   ```

3. **LatÃªncia dentro do target (< 200ms):**
   ```promql
   histogram_quantile(0.99, rate(grpc_request_duration_seconds_bucket[5m]))
   ```

4. **Taxa de sucesso â‰¥ 99.5%:**
   ```promql
   (1 - (rate(grpc_requests_failed_total[5m]) / rate(grpc_requests_total[5m]))) * 100
   ```

---

## ðŸŽ¯ Casos de Uso

### Validar Performance do Sistema

**CenÃ¡rio:** Enviar 100 mensagens e verificar latÃªncia

```bash
# 1. Executar teste de carga
./load-tests/simple-throughput-test.sh

# 2. Abrir Grafana: http://localhost:3000
# 3. Dashboard: Chat4All - System Overview
# 4. Verificar grÃ¡fico "gRPC Latency Percentiles"
# 5. P99 deve estar < 200ms
```

### Investigar Erros

**CenÃ¡rio:** Taxa de erro aumentou

```bash
# 1. Verificar quantos erros
curl -s 'http://localhost:9090/api/v1/query?query=grpc_requests_failed_total' | jq '.data.result[0].value[1]'

# 2. Ver taxa de erro
curl -s 'http://localhost:9090/api/v1/query?query=(rate(grpc_requests_failed_total[5m]) / rate(grpc_requests_total[5m])) * 100' | jq '.data.result[0].value[1]'

# 3. Ver logs do serviÃ§o
docker compose logs -f api-service | grep ERROR
```

### Monitorar Upload de Arquivos

**CenÃ¡rio:** Validar uploads grandes (1GB)

```bash
# 1. Executar teste de upload
python3 test_file_upload.py

# 2. Em outra janela, monitorar mÃ©tricas
watch -n 1 'curl -s http://localhost:8080/metrics | grep file_upload'

# 3. Ver histÃ³rico no Grafana
# Query: rate(file_upload_total[1m])
```

---

## ðŸš€ PrÃ³ximas Melhorias

### Dashboards Adicionais

1. **Infrastructure Health:**
   - CPU/MemÃ³ria dos containers
   - Uso de disco
   - Network I/O

2. **Kafka Performance:**
   - Consumer lag
   - Messages in/out
   - Partition distribution

3. **Cassandra Metrics:**
   - Read/Write latency
   - Query performance
   - Storage usage

4. **Business Metrics:**
   - Mensagens por usuÃ¡rio
   - Arquivos por tamanho
   - DistribuiÃ§Ã£o de canais (WhatsApp, Instagram)

### Alertas Adicionais

- Low throughput (< 10 msg/s quando esperado > 50)
- Kafka consumer lag > 1000
- File upload failures
- WebSocket disconnections > 10%

---

## ðŸ“š ReferÃªncias

- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [PromQL Cheat Sheet](https://promlabs.com/promql-cheat-sheet/)
- [Grafana Dashboard Best Practices](https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/best-practices/)

---

**Ãšltima atualizaÃ§Ã£o:** 07/12/2025  
**VersÃ£o:** 1.0  
**Status:** âœ… Prometheus e Grafana configurados e funcionando
